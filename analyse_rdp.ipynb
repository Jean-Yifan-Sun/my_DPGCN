{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dataset', 'Vanilla train acc', 'Vanilla train loss',\n",
       "       'Vanilla train f1', 'Vanilla test acc', 'Vanilla test loss',\n",
       "       'Vanilla test f1', 'Shadow train acc', 'Shadow train loss',\n",
       "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
       "       'Shadow test f1', 'MIA subsample rate', 'MIA mlp', 'MIA svm',\n",
       "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse',\n",
       "       'MIA confidence thr', 'MIA seed', 'Vanilla runtime per',\n",
       "       'Shadow runtime per', 'Epsilon', 'Delta', 'Dp', 'Rdp', 'Ldp',\n",
       "       'Norm bound', 'Noise scale', 'Sampler', 'Sampler batchsize',\n",
       "       'Occurance k', 'Cluster numparts', 'Saint rootnodes',\n",
       "       'Saint samplecoverage', 'Saint walklenth', 'Epochs', 'Shadow epochs',\n",
       "       'Num val', 'Num test', 'Layers', 'Hidden dims', 'Learning rate',\n",
       "       'Shadow learning rate', 'Dropout', 'Activation', 'Early stopping',\n",
       "       'Patience', 'Optim type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data,Dataset\n",
    "\n",
    "total_parms_new = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params_new.csv',index_col=0)\n",
    "total_parms = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params.csv',index_col=0)\n",
    "\n",
    "from typing import List, Literal, Sequence, Union\n",
    "\n",
    "\n",
    "dataset_list = ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']\n",
    "\n",
    "def get_datasetwise_df(df:pd.DataFrame,name=None):\n",
    "    if not name:\n",
    "        dflist = []\n",
    "        for i in ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']:\n",
    "            dflist.append(df[df['Dataset']==i])\n",
    "        return dflist\n",
    "    else:\n",
    "        return df[df['Dataset']==name]\n",
    "\n",
    "def baseline(df:pd.DataFrame):\n",
    "    clean_adam = df[(df['Dp']==False)&(df['Rdp']==True)&(df['Ldp']==False)&(df['Optim type']=='adam')]\n",
    "    clean_sgd = df[(df['Dp']==False)&(df['Rdp']==True)&(df['Ldp']==False)&(df['Optim type']=='sgd')]\n",
    "    return clean_adam,clean_sgd\n",
    "\n",
    "def rdp_drop(df:pd.DataFrame):\n",
    "    labels = ['Vanilla train acc','Vanilla train loss','Vanilla train f1',\n",
    "          'Shadow train acc', 'Shadow train loss',\n",
    "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
    "       'Shadow test f1', 'MIA subsample rate','MIA seed','Shadow runtime per', 'Num val', 'Num test', 'Layers', 'Hidden dims','Activation','Shadow learning rate','Dropout','Sampler','Dp','Rdp','Ldp']\n",
    "    return df.drop(columns=labels)\n",
    "\n",
    "def get_res_rdp(cora:pd.DataFrame):\n",
    "    maxx = ['Vanilla test acc','Vanilla test f1']\n",
    "    meann = ['Vanilla runtime per','MIA mlp', 'MIA svm','MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse','Epsilon','Delta']\n",
    "    minn = ['Epsilon','Delta']\n",
    "    res = {}\n",
    "   \n",
    "    for k in maxx:\n",
    "        res[k] = cora.max()[k]\n",
    "    for k in meann:\n",
    "        res[k] = cora.mean(numeric_only=True)[k]\n",
    "    for k in minn:\n",
    "        res[k] = cora.mean(numeric_only=True)[k]\n",
    "    return res\n",
    "    \n",
    "\n",
    "total_parms_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = get_datasetwise_df(total_parms_new)\n",
    "cora = dfs[5]\n",
    "cora_adam,cora_sgd = baseline(cora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Sampler batchsize, dtype: float64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_adam_d = cora_adam[cora_adam['Sampler']=='saint_rw']\n",
    "rdp_drop(cora_adam_d)['Sampler batchsize'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': nan,\n",
       " 'Vanilla test f1': nan,\n",
       " 'Vanilla runtime per': nan,\n",
       " 'MIA mlp': nan,\n",
       " 'MIA svm': nan,\n",
       " 'MIA ranfor': nan,\n",
       " 'MIA logi': nan,\n",
       " 'MIA ada': nan,\n",
       " 'MIA confidence mse': nan,\n",
       " 'Epsilon': nan,\n",
       " 'Delta': nan}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_rdp(cora_adam_d[cora_adam_d['Noise scale']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.4\n",
       "Name: Sampler batchsize, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/ress/cora_ns2_nb1_saint_rw.csv',index_col=0)\n",
    "df['Sampler batchsize'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.8062,\n",
       " 'Vanilla test f1': 0.8062,\n",
       " 'Vanilla runtime per': 11.112649999999999,\n",
       " 'MIA mlp': 0.5311999999999999,\n",
       " 'MIA svm': 0.5681499999999999,\n",
       " 'MIA ranfor': 0.52425,\n",
       " 'MIA logi': 0.5234,\n",
       " 'MIA ada': 0.5197,\n",
       " 'MIA confidence mse': 0.59565,\n",
       " 'Epsilon': 1.2177,\n",
       " 'Delta': 0.0}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_rdp(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.2\n",
       "11    0.4\n",
       "Name: Sampler batchsize, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/ress/pho_ns1_nb1_cluster.csv',index_col=0)\n",
    "df['Sampler batchsize'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100.0\n",
       "1     30.0\n",
       "Name: Cluster numparts, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cluster numparts'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.914,\n",
       " 'Vanilla test f1': 0.914,\n",
       " 'Vanilla runtime per': 0.54363,\n",
       " 'MIA mlp': 0.50762,\n",
       " 'MIA svm': 0.51772,\n",
       " 'MIA ranfor': 0.50667,\n",
       " 'MIA logi': 0.5157499999999999,\n",
       " 'MIA ada': 0.50857,\n",
       " 'MIA confidence mse': 0.52007,\n",
       " 'Epsilon': 86.9397,\n",
       " 'Delta': 0.0033}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_rdp(df[(df['Sampler batchsize']==.2)&(df['Cluster numparts']==30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.4\n",
       "1    0.4\n",
       "2    0.4\n",
       "3    0.4\n",
       "4    0.4\n",
       "5    0.4\n",
       "6    0.4\n",
       "7    0.4\n",
       "8    0.4\n",
       "9    0.4\n",
       "Name: Sampler batchsize, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/ress/cora_ns2_nb1_cluster.csv',index_col=0)\n",
    "df['Sampler batchsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610    cluster\n",
       "Name: Sampler, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_adam['Sampler'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610    30.0\n",
       "Name: Cluster numparts, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_adam_d = cora_adam[cora_adam['Sampler']=='cluster']\n",
    "rdp_drop(cora_adam_d)['Cluster numparts'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610    0.4\n",
       "Name: Sampler batchsize, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_adam_d = cora_adam[cora_adam['Sampler']=='cluster']\n",
    "rdp_drop(cora_adam_d)['Sampler batchsize'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610    1.0\n",
       "Name: Noise scale, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_adam_d = cora_adam[cora_adam['Sampler']=='cluster']\n",
    "rdp_drop(cora_adam_d)['Noise scale'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610    1.0\n",
       "Name: Norm bound, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_adam_d = cora_adam[cora_adam['Sampler']=='cluster']\n",
    "rdp_drop(cora_adam_d)['Norm bound'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_sb2_ns1_nb1 = cora_adam_d[(cora_adam_d['Norm bound']==2)&(cora_adam_d['Noise scale']==1)&(cora_adam_d['Sampler batchsize']==.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla train f1</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow train f1</th>\n",
       "      <th>...</th>\n",
       "      <th>Num test</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Hidden dims</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Shadow learning rate</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Early stopping</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Optim type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Dataset, Vanilla train acc, Vanilla train loss, Vanilla train f1, Vanilla test acc, Vanilla test loss, Vanilla test f1, Shadow train acc, Shadow train loss, Shadow train f1, Shadow test acc, Shadow test loss, Shadow test f1, MIA subsample rate, MIA mlp, MIA svm, MIA ranfor, MIA logi, MIA ada, MIA confidence mse, MIA confidence thr, MIA seed, Vanilla runtime per, Shadow runtime per, Epsilon, Delta, Dp, Rdp, Ldp, Norm bound, Noise scale, Sampler, Sampler batchsize, Occurance k, Cluster numparts, Saint rootnodes, Saint samplecoverage, Saint walklenth, Epochs, Shadow epochs, Num val, Num test, Layers, Hidden dims, Learning rate, Shadow learning rate, Dropout, Activation, Early stopping, Patience, Optim type]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 51 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_sb2_ns1_nb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': nan,\n",
       " 'Vanilla test f1': nan,\n",
       " 'Vanilla runtime per': nan,\n",
       " 'MIA mlp': nan,\n",
       " 'MIA svm': nan,\n",
       " 'MIA ranfor': nan,\n",
       " 'MIA logi': nan,\n",
       " 'MIA ada': nan,\n",
       " 'MIA confidence mse': nan,\n",
       " 'Epsilon': nan,\n",
       " 'Delta': nan}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_rdp(cora_sb2_ns1_nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.4\n",
       "Name: Sampler batchsize, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/ress/cora_ns2_nb1_cluster.csv',index_col=0)\n",
    "df['Sampler batchsize'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.7488,\n",
       " 'Vanilla test f1': 0.7488,\n",
       " 'Vanilla runtime per': 0.7607799999999999,\n",
       " 'MIA mlp': 0.50417,\n",
       " 'MIA svm': 0.5147,\n",
       " 'MIA ranfor': 0.50132,\n",
       " 'MIA logi': 0.51298,\n",
       " 'MIA ada': 0.50139,\n",
       " 'MIA confidence mse': 0.58505,\n",
       " 'Epsilon': 47.9038,\n",
       " 'Delta': 0.0033}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_rdp(df[df['Sampler batchsize']==.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.8391,\n",
       " 'Vanilla test f1': 0.8391,\n",
       " 'Vanilla runtime per': 0.76777,\n",
       " 'MIA mlp': 0.5893200000000001,\n",
       " 'MIA svm': 0.60196,\n",
       " 'MIA ranfor': 0.5478799999999999,\n",
       " 'MIA logi': 0.5133,\n",
       " 'MIA ada': 0.55107,\n",
       " 'MIA confidence mse': 0.62348,\n",
       " 'Epsilon': 164.0745,\n",
       " 'Delta': 0.0002}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/ress/cora_ns1_nb1_neighbor.csv',index_col=0)\n",
    "get_res_rdp(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
