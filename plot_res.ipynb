{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data01/sunyifan/work_station/my_gcn/out/citeseer/Privacy_True_shadow/MIA_tsts_0.5_0.1_5.0_1_result.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m path1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMIA_tsts_0.5_0.1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_1_result.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMIA_tsts_0.5_1.0_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_1_result.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m citeseer_dfs\u001b[38;5;241m.\u001b[39mappend( \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mciteseer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m cora_dfs\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cora,path1),index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     14\u001b[0m pubmed_dfs\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pubmed,path2),index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/mnt/ssd1/sunyifan/conda/mygcn/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd1/sunyifan/conda/mygcn/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/mnt/ssd1/sunyifan/conda/mygcn/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd1/sunyifan/conda/mygcn/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/mnt/ssd1/sunyifan/conda/mygcn/lib/python3.9/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data01/sunyifan/work_station/my_gcn/out/citeseer/Privacy_True_shadow/MIA_tsts_0.5_0.1_5.0_1_result.csv'"
     ]
    }
   ],
   "source": [
    "citeseer = '/data01/sunyifan/work_station/my_gcn/out/citeseer/Privacy_True_shadow'\n",
    "cora = '/data01/sunyifan/work_station/my_gcn/out/cora/Privacy_True_shadow'\n",
    "pubmed = '/data01/sunyifan/work_station/my_gcn/out/pubmed/Privacy_True_shadow'\n",
    "\n",
    "\n",
    "citeseer_dfs = []\n",
    "cora_dfs = []\n",
    "pubmed_dfs = []\n",
    "for i in [5.0,10.0,15.0,20.0,25.0,30.0,35.0,40.0]:\n",
    "    path1 = f'MIA_tsts_0.5_0.1_{i}_1_result.csv'\n",
    "    path2 = f'MIA_tsts_0.5_1.0_{i}_1_result.csv'\n",
    "    citeseer_dfs.append( pd.read_csv(os.path.join(citeseer,path1),index_col=0))\n",
    "    cora_dfs.append(pd.read_csv(os.path.join(cora,path1),index_col=0))\n",
    "    pubmed_dfs.append(pd.read_csv(os.path.join(pubmed,path2),index_col=0))\n",
    "citeseer_dfs = pd.concat(citeseer_dfs,ignore_index=True)\n",
    "pubmed_dfs = pd.concat(pubmed_dfs,ignore_index=True)\n",
    "cora_dfs = pd.concat(cora_dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow test acc</th>\n",
       "      <th>Shadow test loss</th>\n",
       "      <th>MIA mlp</th>\n",
       "      <th>MIA svm</th>\n",
       "      <th>MIA ranfor</th>\n",
       "      <th>MIA logi</th>\n",
       "      <th>MIA ada</th>\n",
       "      <th>MIA confidence mse</th>\n",
       "      <th>MIA confidence thr</th>\n",
       "      <th>MIA seed</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9787</td>\n",
       "      <td>1057.3943</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>451859.2188</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>5.7347</td>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5049</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.01</td>\n",
       "      <td>123454321</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9869</td>\n",
       "      <td>829.7454</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>450835.2188</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>4.0922</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.5049</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>0.01</td>\n",
       "      <td>246908642</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9803</td>\n",
       "      <td>751.3455</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>420292.1250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>4.6091</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>0.01</td>\n",
       "      <td>370362963</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9869</td>\n",
       "      <td>546.4952</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>432394.0625</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>3.6158</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.6691</td>\n",
       "      <td>0.01</td>\n",
       "      <td>493817284</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9869</td>\n",
       "      <td>353.9183</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>497618.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7947</td>\n",
       "      <td>4.0390</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.01</td>\n",
       "      <td>617271605</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.9163</td>\n",
       "      <td>14632.2432</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>497760.8438</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>3.9604</td>\n",
       "      <td>0.5312</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>0.01</td>\n",
       "      <td>740725926</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.9130</td>\n",
       "      <td>12184.4678</td>\n",
       "      <td>0.6437</td>\n",
       "      <td>473898.5625</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>5.7088</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>0.01</td>\n",
       "      <td>864180247</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.9228</td>\n",
       "      <td>9607.1758</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>534132.8125</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>5.3399</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.6453</td>\n",
       "      <td>0.01</td>\n",
       "      <td>987634568</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.9261</td>\n",
       "      <td>9272.4229</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>402855.0000</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>4.2398</td>\n",
       "      <td>0.5041</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1111088889</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.8703</td>\n",
       "      <td>17035.0312</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>450677.8438</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>4.5464</td>\n",
       "      <td>0.4869</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.4951</td>\n",
       "      <td>0.4885</td>\n",
       "      <td>0.4951</td>\n",
       "      <td>0.6273</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1234543210</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vanilla train acc  Vanilla train loss  Vanilla test acc  \\\n",
       "0              0.9787           1057.3943            0.6585   \n",
       "1              0.9869            829.7454            0.6650   \n",
       "2              0.9803            751.3455            0.6470   \n",
       "3              0.9869            546.4952            0.6519   \n",
       "4              0.9869            353.9183            0.6814   \n",
       "..                ...                 ...               ...   \n",
       "75             0.9163          14632.2432            0.6158   \n",
       "76             0.9130          12184.4678            0.6437   \n",
       "77             0.9228           9607.1758            0.6240   \n",
       "78             0.9261           9272.4229            0.6535   \n",
       "79             0.8703          17035.0312            0.6223   \n",
       "\n",
       "    Vanilla test loss  Shadow train acc  Shadow train loss  Shadow test acc  \\\n",
       "0         451859.2188            0.9984             0.0023           0.7668   \n",
       "1         450835.2188            0.9967             0.0046           0.7882   \n",
       "2         420292.1250            1.0000             0.0000           0.7553   \n",
       "3         432394.0625            0.9934             0.0092           0.7882   \n",
       "4         497618.7500            1.0000             0.0000           0.7947   \n",
       "..                ...               ...                ...              ...   \n",
       "75        497760.8438            0.9984             0.0023           0.7980   \n",
       "76        473898.5625            0.9934             0.0091           0.7356   \n",
       "77        534132.8125            0.9967             0.0046           0.7750   \n",
       "78        402855.0000            0.9951             0.0068           0.7603   \n",
       "79        450677.8438            0.9934             0.0091           0.7586   \n",
       "\n",
       "    Shadow test loss  MIA mlp  MIA svm  MIA ranfor  MIA logi  MIA ada  \\\n",
       "0             5.7347   0.5033   0.5033      0.5000    0.5049   0.5000   \n",
       "1             4.0922   0.5107   0.5123      0.5025    0.5049   0.5025   \n",
       "2             4.6091   0.5115   0.5246      0.5000    0.5115   0.5000   \n",
       "3             3.6158   0.5263   0.5263      0.5345    0.5263   0.5345   \n",
       "4             4.0390   0.5016   0.5016      0.5000    0.5016   0.5000   \n",
       "..               ...      ...      ...         ...       ...      ...   \n",
       "75            3.9604   0.5312   0.5238      0.5000    0.5238   0.5000   \n",
       "76            5.7088   0.4926   0.4901      0.5074    0.4901   0.5074   \n",
       "77            5.3399   0.5066   0.4959      0.4926    0.4959   0.4926   \n",
       "78            4.2398   0.5041   0.5025      0.4992    0.5008   0.4992   \n",
       "79            4.5464   0.4869   0.4885      0.4951    0.4885   0.4951   \n",
       "\n",
       "    MIA confidence mse  MIA confidence thr    MIA seed  epsilon  delta  \n",
       "0               0.6601                0.01   123454321  31.5129    0.0  \n",
       "1               0.6593                0.01   246908642  31.5129    0.0  \n",
       "2               0.6683                0.01   370362963  31.5129    0.0  \n",
       "3               0.6691                0.01   493817284  31.5129    0.0  \n",
       "4               0.6552                0.01   617271605  31.5129    0.0  \n",
       "..                 ...                 ...         ...      ...    ...  \n",
       "75              0.6494                0.01   740725926   2.8417    0.0  \n",
       "76              0.6305                0.01   864180247   2.8417    0.0  \n",
       "77              0.6453                0.01   987634568   2.8417    0.0  \n",
       "78              0.6412                0.01  1111088889   2.8417    0.0  \n",
       "79              0.6273                0.01  1234543210   2.8417    0.0  \n",
       "\n",
       "[80 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_dfs['Vanilla train acc']\n",
    "cora_dfs['Vanilla test acc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow test acc</th>\n",
       "      <th>Shadow test loss</th>\n",
       "      <th>MIA mlp</th>\n",
       "      <th>MIA svm</th>\n",
       "      <th>MIA ranfor</th>\n",
       "      <th>MIA logi</th>\n",
       "      <th>MIA ada</th>\n",
       "      <th>MIA confidence mse</th>\n",
       "      <th>MIA confidence thr</th>\n",
       "      <th>MIA seed</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5581</td>\n",
       "      <td>25627.0996</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>83769.7266</td>\n",
       "      <td>0.9457</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>1.2756</td>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.5053</td>\n",
       "      <td>0.4947</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.01</td>\n",
       "      <td>123454321</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6546</td>\n",
       "      <td>36084.4609</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>96014.5625</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.01</td>\n",
       "      <td>246908642</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5533</td>\n",
       "      <td>27036.6641</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>74866.9453</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.5936</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>1.1795</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.5143</td>\n",
       "      <td>0.80</td>\n",
       "      <td>370362963</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5283</td>\n",
       "      <td>28241.4492</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>80968.5703</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>0.8093</td>\n",
       "      <td>1.6010</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.5044</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>0.74</td>\n",
       "      <td>493817284</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5705</td>\n",
       "      <td>29081.0645</td>\n",
       "      <td>0.5381</td>\n",
       "      <td>79166.0312</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>1.3781</td>\n",
       "      <td>0.5044</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.5042</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.01</td>\n",
       "      <td>617271605</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.7042</td>\n",
       "      <td>363587.3750</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>490604.2188</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.7946</td>\n",
       "      <td>2.3124</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.01</td>\n",
       "      <td>740725926</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.7161</td>\n",
       "      <td>373071.5312</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>479842.2188</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>1.0600</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>1.0715</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5114</td>\n",
       "      <td>0.01</td>\n",
       "      <td>864180247</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.7276</td>\n",
       "      <td>291621.9062</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>386067.9688</td>\n",
       "      <td>0.7371</td>\n",
       "      <td>0.5253</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.01</td>\n",
       "      <td>987634568</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.7118</td>\n",
       "      <td>331630.3438</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>514232.9688</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>1.1907</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1111088889</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.7134</td>\n",
       "      <td>416170.8438</td>\n",
       "      <td>0.6961</td>\n",
       "      <td>477104.3750</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.8221</td>\n",
       "      <td>1.1554</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1234543210</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vanilla train acc  Vanilla train loss  Vanilla test acc  \\\n",
       "0              0.5581          25627.0996            0.5417   \n",
       "1              0.6546          36084.4609            0.6105   \n",
       "2              0.5533          27036.6641            0.5108   \n",
       "3              0.5283          28241.4492            0.5295   \n",
       "4              0.5705          29081.0645            0.5381   \n",
       "..                ...                 ...               ...   \n",
       "75             0.7042         363587.3750            0.6878   \n",
       "76             0.7161         373071.5312            0.6907   \n",
       "77             0.7276         291621.9062            0.6939   \n",
       "78             0.7118         331630.3438            0.6163   \n",
       "79             0.7134         416170.8438            0.6961   \n",
       "\n",
       "    Vanilla test loss  Shadow train acc  Shadow train loss  Shadow test acc  \\\n",
       "0          83769.7266            0.9457             0.1893           0.8025   \n",
       "1          96014.5625            0.8343             0.4721           0.7477   \n",
       "2          74866.9453            0.7073             0.5936           0.6066   \n",
       "3          80968.5703            0.9517             0.1524           0.8093   \n",
       "4          79166.0312            0.9470             0.1811           0.7942   \n",
       "..                ...               ...                ...              ...   \n",
       "75        490604.2188            0.9646             0.1380           0.7946   \n",
       "76        479842.2188            0.4056             1.0600           0.3918   \n",
       "77        386067.9688            0.7371             0.5253           0.6756   \n",
       "78        514232.9688            0.9087             0.3150           0.7759   \n",
       "79        477104.3750            0.9382             0.1846           0.8221   \n",
       "\n",
       "    Shadow test loss  MIA mlp  MIA svm  MIA ranfor  MIA logi  MIA ada  \\\n",
       "0             1.2756   0.5013   0.5013      0.4959    0.5053   0.4947   \n",
       "1             0.7729   0.5026   0.5026      0.4944    0.5026   0.4944   \n",
       "2             1.1795   0.5035   0.5035      0.5002    0.5035   0.5001   \n",
       "3             1.6010   0.5027   0.5027      0.5044    0.5027   0.5045   \n",
       "4             1.3781   0.5044   0.4954      0.4998    0.4954   0.5042   \n",
       "..               ...      ...      ...         ...       ...      ...   \n",
       "75            2.3124   0.5000   0.5039      0.5000    0.5033   0.5000   \n",
       "76            1.0715   0.5000   0.5000      0.5000    0.5095   0.5000   \n",
       "77            0.8952   0.5027   0.5000      0.5000    0.4993   0.5000   \n",
       "78            1.1907   0.5076   0.4971      0.5076    0.4895   0.5076   \n",
       "79            1.1554   0.5026   0.5026      0.5000    0.5026   0.5000   \n",
       "\n",
       "    MIA confidence mse  MIA confidence thr    MIA seed  epsilon  delta  \n",
       "0               0.5066                0.01   123454321  31.5129    0.0  \n",
       "1               0.5238                0.01   246908642  31.5129    0.0  \n",
       "2               0.5143                0.80   370362963  31.5129    0.0  \n",
       "3               0.5122                0.74   493817284  31.5129    0.0  \n",
       "4               0.5107                0.01   617271605  31.5129    0.0  \n",
       "..                 ...                 ...         ...      ...    ...  \n",
       "75              0.5068                0.01   740725926   2.8417    0.0  \n",
       "76              0.5114                0.01   864180247   2.8417    0.0  \n",
       "77              0.5070                0.01   987634568   2.8417    0.0  \n",
       "78              0.5056                0.01  1111088889   2.8417    0.0  \n",
       "79              0.5101                0.01  1234543210   2.8417    0.0  \n",
       "\n",
       "[80 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow test acc</th>\n",
       "      <th>Shadow test loss</th>\n",
       "      <th>MIA mlp</th>\n",
       "      <th>MIA svm</th>\n",
       "      <th>MIA ranfor</th>\n",
       "      <th>MIA logi</th>\n",
       "      <th>MIA ada</th>\n",
       "      <th>MIA confidence mse</th>\n",
       "      <th>MIA confidence thr</th>\n",
       "      <th>MIA seed</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9693</td>\n",
       "      <td>1843.7460</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>1.052846e+06</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>8.1860</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>0.5102</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>0.01</td>\n",
       "      <td>123454321</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9746</td>\n",
       "      <td>1792.3137</td>\n",
       "      <td>0.5561</td>\n",
       "      <td>8.777741e+05</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.6511</td>\n",
       "      <td>7.2966</td>\n",
       "      <td>0.4827</td>\n",
       "      <td>0.4982</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>246908642</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9786</td>\n",
       "      <td>1409.7367</td>\n",
       "      <td>0.5682</td>\n",
       "      <td>8.655594e+05</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>10.3950</td>\n",
       "      <td>0.4894</td>\n",
       "      <td>0.4894</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4894</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7047</td>\n",
       "      <td>0.01</td>\n",
       "      <td>370362963</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9586</td>\n",
       "      <td>4078.6182</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>8.539014e+05</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>10.7758</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>0.01</td>\n",
       "      <td>493817284</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9693</td>\n",
       "      <td>2105.8162</td>\n",
       "      <td>0.5361</td>\n",
       "      <td>9.597656e+05</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.6070</td>\n",
       "      <td>9.2836</td>\n",
       "      <td>0.4984</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5030</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.01</td>\n",
       "      <td>617271605</td>\n",
       "      <td>31.5129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.9146</td>\n",
       "      <td>12631.7207</td>\n",
       "      <td>0.5856</td>\n",
       "      <td>9.659272e+05</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>8.2170</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.01</td>\n",
       "      <td>740725926</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.8932</td>\n",
       "      <td>18359.1094</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>9.962488e+05</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>8.7756</td>\n",
       "      <td>0.5044</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.01</td>\n",
       "      <td>864180247</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.9172</td>\n",
       "      <td>11668.7051</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>9.348501e+05</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>8.2055</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.01</td>\n",
       "      <td>987634568</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.8959</td>\n",
       "      <td>16468.8125</td>\n",
       "      <td>0.5254</td>\n",
       "      <td>1.043074e+06</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>6.8850</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1111088889</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.8999</td>\n",
       "      <td>13712.8242</td>\n",
       "      <td>0.5294</td>\n",
       "      <td>1.026055e+06</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>7.5842</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4803</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6887</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1234543210</td>\n",
       "      <td>2.8417</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vanilla train acc  Vanilla train loss  Vanilla test acc  \\\n",
       "0              0.9693           1843.7460            0.5468   \n",
       "1              0.9746           1792.3137            0.5561   \n",
       "2              0.9786           1409.7367            0.5682   \n",
       "3              0.9586           4078.6182            0.5789   \n",
       "4              0.9693           2105.8162            0.5361   \n",
       "..                ...                 ...               ...   \n",
       "75             0.9146          12631.7207            0.5856   \n",
       "76             0.8932          18359.1094            0.5602   \n",
       "77             0.9172          11668.7051            0.5575   \n",
       "78             0.8959          16468.8125            0.5254   \n",
       "79             0.8999          13712.8242            0.5294   \n",
       "\n",
       "    Vanilla test loss  Shadow train acc  Shadow train loss  Shadow test acc  \\\n",
       "0        1.052846e+06            0.9907             0.0133           0.6310   \n",
       "1        8.777741e+05            0.9880             0.0167           0.6511   \n",
       "2        8.655594e+05            0.9907             0.0131           0.6711   \n",
       "3        8.539014e+05            0.9853             0.0212           0.6297   \n",
       "4        9.597656e+05            0.9853             0.0213           0.6070   \n",
       "..                ...               ...                ...              ...   \n",
       "75       9.659272e+05            0.9866             0.0202           0.6390   \n",
       "76       9.962488e+05            0.9920             0.0113           0.6591   \n",
       "77       9.348501e+05            0.9826             0.0245           0.5909   \n",
       "78       1.043074e+06            0.9840             0.0229           0.6805   \n",
       "79       1.026055e+06            0.9813             0.0269           0.6444   \n",
       "\n",
       "    Shadow test loss  MIA mlp  MIA svm  MIA ranfor  MIA logi  MIA ada  \\\n",
       "0             8.1860   0.5076   0.5102      0.5000    0.5076   0.5000   \n",
       "1             7.2966   0.4827   0.4982      0.5000    0.5031   0.5000   \n",
       "2            10.3950   0.4894   0.4894      0.5000    0.4894   0.5000   \n",
       "3            10.7758   0.5110   0.5110      0.5062    0.5110   0.5062   \n",
       "4             9.2836   0.4984   0.5030      0.5000    0.5030   0.5000   \n",
       "..               ...      ...      ...         ...       ...      ...   \n",
       "75            8.2170   0.4977   0.4901      0.5000    0.4977   0.5000   \n",
       "76            8.7756   0.5044   0.4889      0.5000    0.4889   0.5000   \n",
       "77            8.2055   0.4861   0.4861      0.5000    0.5016   0.4861   \n",
       "78            6.8850   0.5000   0.5218      0.5000    0.5218   0.5000   \n",
       "79            7.5842   0.4648   0.4803      0.5000    0.4803   0.5000   \n",
       "\n",
       "    MIA confidence mse  MIA confidence thr    MIA seed  epsilon  delta  \n",
       "0               0.7128                0.01   123454321  31.5129    0.0  \n",
       "1               0.7101                0.01   246908642  31.5129    0.0  \n",
       "2               0.7047                0.01   370362963  31.5129    0.0  \n",
       "3               0.6921                0.01   493817284  31.5129    0.0  \n",
       "4               0.7174                0.01   617271605  31.5129    0.0  \n",
       "..                 ...                 ...         ...      ...    ...  \n",
       "75              0.6613                0.01   740725926   2.8417    0.0  \n",
       "76              0.6700                0.01   864180247   2.8417    0.0  \n",
       "77              0.6807                0.01   987634568   2.8417    0.0  \n",
       "78              0.6860                0.01  1111088889   2.8417    0.0  \n",
       "79              0.6887                0.01  1234543210   2.8417    0.0  \n",
       "\n",
       "[80 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citeseer_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd1/sunyifan/conda/mygcn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla train f1</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow train f1</th>\n",
       "      <th>...</th>\n",
       "      <th>Num test</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Hidden dims</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Shadow learning rate</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Early stopping</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Optim type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.7609</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.9409</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.9409</td>\n",
       "      <td>0.7997</td>\n",
       "      <td>0.6530</td>\n",
       "      <td>0.7997</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.2503</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Vanilla train acc  Vanilla train loss  Vanilla train f1  \\\n",
       "0    cora             0.9540              0.1810            0.9540   \n",
       "1    cora             0.9409              0.2279            0.9409   \n",
       "2    cora             0.9376              0.2133            0.9376   \n",
       "3    cora             0.9376              0.2503            0.9376   \n",
       "4    cora             0.9475              0.1974            0.9475   \n",
       "\n",
       "   Vanilla test acc  Vanilla test loss  Vanilla test f1  Shadow train acc  \\\n",
       "0            0.7619             0.7609           0.7619            0.9984   \n",
       "1            0.7997             0.6530           0.7997            0.9951   \n",
       "2            0.7750             0.6869           0.7750            0.9885   \n",
       "3            0.7849             0.6726           0.7849            0.9967   \n",
       "4            0.7882             0.6678           0.7882            0.9967   \n",
       "\n",
       "   Shadow train loss  Shadow train f1  ...  Num test  Layers  Hidden dims  \\\n",
       "0             0.0296           0.9984  ...      0.45       2          256   \n",
       "1             0.0263           0.9951  ...      0.45       2          256   \n",
       "2             0.0441           0.9885  ...      0.45       2          256   \n",
       "3             0.0196           0.9967  ...      0.45       2          256   \n",
       "4             0.0345           0.9967  ...      0.45       2          256   \n",
       "\n",
       "   Learning rate  Shadow learning rate  Dropout  Activation  Early stopping  \\\n",
       "0          0.005                 0.001      0.0        relu            True   \n",
       "1          0.005                 0.001      0.0        relu            True   \n",
       "2          0.005                 0.001      0.0        relu            True   \n",
       "3          0.005                 0.001      0.0        relu            True   \n",
       "4          0.005                 0.001      0.0        relu            True   \n",
       "\n",
       "   Patience  Optim type  \n",
       "0       100        adam  \n",
       "1       100        adam  \n",
       "2       100        adam  \n",
       "3       100        adam  \n",
       "4       100        adam  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data,Dataset\n",
    "\n",
    "total_parms = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params.csv',index_col=0)\n",
    "total_parms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1010 entries, 0 to 1009\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Dataset               1010 non-null   object \n",
      " 1   Vanilla train acc     1010 non-null   float64\n",
      " 2   Vanilla train loss    1010 non-null   float64\n",
      " 3   Vanilla train f1      1010 non-null   float64\n",
      " 4   Vanilla test acc      1010 non-null   float64\n",
      " 5   Vanilla test loss     1010 non-null   float64\n",
      " 6   Vanilla test f1       1010 non-null   float64\n",
      " 7   Shadow train acc      1010 non-null   float64\n",
      " 8   Shadow train loss     1010 non-null   float64\n",
      " 9   Shadow train f1       1010 non-null   float64\n",
      " 10  Shadow test acc       1010 non-null   float64\n",
      " 11  Shadow test loss      1010 non-null   float64\n",
      " 12  Shadow test f1        1010 non-null   float64\n",
      " 13  MIA subsample rate    1010 non-null   float64\n",
      " 14  MIA mlp               1010 non-null   float64\n",
      " 15  MIA svm               1010 non-null   float64\n",
      " 16  MIA ranfor            1010 non-null   float64\n",
      " 17  MIA logi              1010 non-null   float64\n",
      " 18  MIA ada               1010 non-null   float64\n",
      " 19  MIA confidence mse    1010 non-null   float64\n",
      " 20  MIA confidence thr    1010 non-null   float64\n",
      " 21  MIA seed              1010 non-null   int64  \n",
      " 22  Vanilla runtime per   1010 non-null   float64\n",
      " 23  Shadow runtime per    1010 non-null   float64\n",
      " 24  Epsilon               1010 non-null   float64\n",
      " 25  Delta                 1010 non-null   float64\n",
      " 26  Dp                    1010 non-null   bool   \n",
      " 27  Rdp                   1010 non-null   bool   \n",
      " 28  Ldp                   1010 non-null   bool   \n",
      " 29  Sampler               1010 non-null   object \n",
      " 30  Sampler batchsize     1010 non-null   float64\n",
      " 31  Occurance k           1010 non-null   int64  \n",
      " 32  Cluster numparts      1010 non-null   int64  \n",
      " 33  Saint rootnodes       1010 non-null   int64  \n",
      " 34  Saint samplecoverage  1010 non-null   int64  \n",
      " 35  Saint walklenth       1010 non-null   int64  \n",
      " 36  Epochs                1010 non-null   int64  \n",
      " 37  Shadow epochs         1010 non-null   int64  \n",
      " 38  Num val               1010 non-null   float64\n",
      " 39  Num test              1010 non-null   float64\n",
      " 40  Layers                1010 non-null   int64  \n",
      " 41  Hidden dims           1010 non-null   int64  \n",
      " 42  Learning rate         1010 non-null   float64\n",
      " 43  Shadow learning rate  1010 non-null   float64\n",
      " 44  Dropout               1010 non-null   float64\n",
      " 45  Activation            1010 non-null   object \n",
      " 46  Early stopping        1010 non-null   bool   \n",
      " 47  Patience              1010 non-null   int64  \n",
      " 48  Optim type            1010 non-null   object \n",
      "dtypes: bool(4), float64(30), int64(11), object(4)\n",
      "memory usage: 366.9+ KB\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Literal, Sequence, Union\n",
    "\n",
    "\n",
    "dataset_list = ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']\n",
    "def get_datasetwise_df(df:pd.DataFrame,name=None):\n",
    "    if not name:\n",
    "        dflist = []\n",
    "        for i in ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']:\n",
    "            dflist.append(df[df['Dataset']==i])\n",
    "        return dflist\n",
    "    else:\n",
    "        return df[df['Dataset']==name]\n",
    "\n",
    "def get_f1accs(df: Union[pd.DataFrame, List[pd.DataFrame]]):\n",
    "    metrics = ['Vanilla test acc','Vanilla test f1','Shadow test acc','Shadow test f1','MIA mlp', 'MIA svm',\n",
    "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse','Vanilla runtime per']\n",
    "    if isinstance(df,list):\n",
    "        res = []\n",
    "        for i in df:\n",
    "            res.append(i[metrics].max())\n",
    "        return res\n",
    "    else:\n",
    "        return df[metrics].max()\n",
    "    \n",
    "\n",
    "total_parms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dataset', 'Vanilla train acc', 'Vanilla train loss',\n",
       "       'Vanilla train f1', 'Vanilla test acc', 'Vanilla test loss',\n",
       "       'Vanilla test f1', 'Shadow train acc', 'Shadow train loss',\n",
       "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
       "       'Shadow test f1', 'MIA subsample rate', 'MIA mlp', 'MIA svm',\n",
       "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse',\n",
       "       'MIA confidence thr', 'MIA seed', 'Vanilla runtime per',\n",
       "       'Shadow runtime per', 'Epsilon', 'Delta', 'Dp', 'Rdp', 'Ldp', 'Sampler',\n",
       "       'Sampler batchsize', 'Occurance k', 'Cluster numparts',\n",
       "       'Saint rootnodes', 'Saint samplecoverage', 'Saint walklenth', 'Epochs',\n",
       "       'Shadow epochs', 'Num val', 'Num test', 'Layers', 'Hidden dims',\n",
       "       'Learning rate', 'Shadow learning rate', 'Dropout', 'Activation',\n",
       "       'Early stopping', 'Patience', 'Optim type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_parms.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vanilla test acc      NaN\n",
       "Vanilla test f1       NaN\n",
       "Shadow test acc       NaN\n",
       "Shadow test f1        NaN\n",
       "MIA mlp               NaN\n",
       "MIA svm               NaN\n",
       "MIA ranfor            NaN\n",
       "MIA logi              NaN\n",
       "MIA ada               NaN\n",
       "MIA confidence mse    NaN\n",
       "Vanilla runtime per   NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ = total_parms[(total_parms['Dp']==False)&(total_parms['Rdp']==False)&(total_parms['Ldp']==False)]\n",
    "clean_list = get_datasetwise_df(clean_)\n",
    "clean_cora = clean_list[0]\n",
    "get_f1accs(clean_cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_res_dfs = get_f1accs(clean_list)\n",
    "clean_res = {}\n",
    "for i in range(len(dataset_list)):\n",
    "    clean_res[dataset_list[i]] = clean_res_dfs[i].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cora</th>\n",
       "      <th>citeseer</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>computers</th>\n",
       "      <th>photo</th>\n",
       "      <th>cs</th>\n",
       "      <th>physics</th>\n",
       "      <th>reddit</th>\n",
       "      <th>github</th>\n",
       "      <th>flickr</th>\n",
       "      <th>lastfmasia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <td>0.8046</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>0.9115</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.8197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <td>0.8046</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>0.9115</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.8197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shadow test acc</th>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.8186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shadow test f1</th>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.8186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIA mlp</th>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.5321</td>\n",
       "      <td>0.5448</td>\n",
       "      <td>0.5704</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>0.5788</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>0.5913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIA svm</th>\n",
       "      <td>0.5952</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.5564</td>\n",
       "      <td>0.5257</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.5751</td>\n",
       "      <td>0.6019</td>\n",
       "      <td>0.5778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIA ranfor</th>\n",
       "      <td>0.6544</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.5105</td>\n",
       "      <td>0.5234</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.6108</td>\n",
       "      <td>0.5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIA logi</th>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.5103</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.5037</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>0.5279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIA ada</th>\n",
       "      <td>0.6675</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>0.5284</td>\n",
       "      <td>0.5252</td>\n",
       "      <td>0.5736</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>0.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIA confidence mse</th>\n",
       "      <td>0.6897</td>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.7891</td>\n",
       "      <td>0.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla runtime per</th>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>0.1830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cora  citeseer  pubmed  computers   photo      cs  \\\n",
       "Vanilla test acc     0.8046    0.6845  0.8510     0.9011  0.9355  0.9115   \n",
       "Vanilla test f1      0.8046    0.6845  0.8510     0.9011  0.9355  0.9115   \n",
       "Shadow test acc      0.8161    0.6885  0.8510     0.9053  0.9366  0.9057   \n",
       "Shadow test f1       0.8161    0.6885  0.8510     0.9053  0.9366  0.9057   \n",
       "MIA mlp              0.6527    0.6839  0.5130     0.5321  0.5448  0.5704   \n",
       "MIA svm              0.5952    0.6110  0.5145     0.5300  0.5346  0.5564   \n",
       "MIA ranfor           0.6544    0.7140  0.5105     0.5234  0.5302  0.5580   \n",
       "MIA logi             0.5353    0.5303  0.5115     0.5190  0.5218  0.5221   \n",
       "MIA ada              0.6675    0.7120  0.5209     0.5339  0.5331  0.5663   \n",
       "MIA confidence mse   0.6897    0.7535  0.5536     0.5523  0.5453  0.5862   \n",
       "Vanilla runtime per  0.1820    0.1833  0.1780     0.1875  0.1847  0.1951   \n",
       "\n",
       "                     physics  reddit  github  flickr  lastfmasia  \n",
       "Vanilla test acc      0.9476  0.9170  0.8273  0.3982      0.8197  \n",
       "Vanilla test f1       0.9476  0.9170  0.8273  0.3982      0.8197  \n",
       "Shadow test acc       0.9492  0.9174  0.8299  0.4037      0.8186  \n",
       "Shadow test f1        0.9492  0.9174  0.8299  0.4037      0.8186  \n",
       "MIA mlp               0.5302  0.5239  0.5788  0.6023      0.5913  \n",
       "MIA svm               0.5257  0.5282  0.5751  0.6019      0.5778  \n",
       "MIA ranfor            0.5248  0.5210  0.5396  0.6108      0.5842  \n",
       "MIA logi              0.5103  0.5189  0.5037  0.5367      0.5279  \n",
       "MIA ada               0.5284  0.5252  0.5736  0.6217      0.5860  \n",
       "MIA confidence mse    0.5440  0.5434  0.6301  0.7891      0.6259  \n",
       "Vanilla runtime per   0.1945  0.2206  0.1763  0.1831      0.1830  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clean_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from utils import *\n",
    "def get_dataloader(dataset='cora', num_val=.1, num_test=.45,shadow_set=False,mia_subsample_rate=.5):\n",
    "        '''\n",
    "        Prepares the dataloader for a particular split of the data.\n",
    "        '''\n",
    "        if dataset == 'cora':\n",
    "            data = get_dataset(cls=\"Planetoid\",name=\"Cora\",num_test=num_test,num_val=num_val)\n",
    "\n",
    "        elif dataset == 'citeseer':\n",
    "            data = get_dataset(cls=\"Planetoid\",name=\"CiteSeer\",num_test=num_test,num_val=num_val)\n",
    "\n",
    "        elif dataset == 'pubmed':\n",
    "            data = get_dataset(cls=\"Planetoid\",name=\"PubMed\",num_test=num_test,num_val=num_val)\n",
    "\n",
    "        elif dataset == 'computers':\n",
    "            data = get_dataset(cls=\"Amazon\",name=\"Computers\",num_test=num_test,num_val=num_val)\n",
    "\n",
    "        elif dataset == 'photo':\n",
    "            data = get_dataset(cls=\"Amazon\",name=\"Photo\",num_test=num_test,num_val=num_val)\n",
    "\n",
    "        elif dataset == 'cs':\n",
    "            data = get_dataset(cls=\"Coauthor\",name=\"CS\",num_test=num_test,num_val=num_val)\n",
    "\n",
    "        elif dataset == 'physics':\n",
    "            data = get_dataset(cls=\"Coauthor\",name=\"Physics\",num_test=num_test,num_val=num_val)\n",
    "\n",
    "        elif dataset == 'reddit':\n",
    "            data = get_dataset(cls=\"Reddit\")\n",
    "        \n",
    "        elif dataset == 'flickr':\n",
    "            data = get_dataset(cls=\"Flickr\")\n",
    "        elif dataset == 'github':\n",
    "            data = get_dataset(cls=\"GitHub\")\n",
    "        elif dataset == 'lastfmasia':\n",
    "            data = get_dataset(cls=\"LastFMAsia\")\n",
    "        elif dataset in ['RU','PT','DE','FR','ES','EN']:\n",
    "            data = get_dataset(cls=\"Twitch\",name=dataset)\n",
    "        else:\n",
    "            raise Exception(\"Incorrect dataset specified.\")\n",
    "        # data = node_split(data[0],num_val=num_val,num_test=num_test)\n",
    "        raw_data = data[0]\n",
    "        vanilla,shadow = subsample_graph_both_pyg(data=raw_data,rate=mia_subsample_rate)\n",
    "        # vanilla,shadow = subsample_mask_graph_full(data,mia_subsample_rate)\n",
    "        print(f\"\\nGet dataset {dataset}\\n\")\n",
    "        if shadow_set:\n",
    "            print(\"Shadow dataset Subsampling graph...\")\n",
    "            # subsample_graph(shadow_data, rate=self.mia_subsample_rate,\n",
    "                            # maintain_class_dists=True)\n",
    "            data = shadow\n",
    "            data = node_split(data,num_val=num_val,num_test=num_test)\n",
    "            \n",
    "            print(f\"Shadow: Total number of nodes: {data.x.shape[0]}\")\n",
    "            print(f\"Shadow: Total number of edges: {data.edge_index.shape[1]}\")\n",
    "            print(f\"Shadow: Number of train nodes: {data.train_mask.sum().item()}\")\n",
    "            print(f\"Shadow: Number of validation nodes: {data.val_mask.sum().item()}\")\n",
    "            print(f\"Shadow: Number of test nodes: {data.test_mask.sum().item()}\")\n",
    "        else:\n",
    "            data = vanilla\n",
    "            data = node_split(data,num_val=num_val,num_test=num_test)\n",
    "            print(f\"Total number of nodes: {data.x.shape[0]}\")\n",
    "            print(f\"Total number of edges: {data.edge_index.shape[1]}\")\n",
    "            print(f\"Number of train nodes: {data.train_mask.sum().item()}\")\n",
    "            print(f\"Number of validation nodes: {data.val_mask.sum().item()}\")\n",
    "            print(f\"Number of test nodes: {data.test_mask.sum().item()}\")\n",
    "        return data,raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset cora\n",
      "\n",
      "Total number of nodes: 1353\n",
      "Total number of edges: 2834\n",
      "Number of train nodes: 609\n",
      "Number of validation nodes: 135\n",
      "Number of test nodes: 609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_tr,cora = get_dataloader('cora')\n",
    "cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset pubmed\n",
      "\n",
      "Total number of nodes: 9857\n",
      "Total number of edges: 22574\n",
      "Number of train nodes: 4435\n",
      "Number of validation nodes: 986\n",
      "Number of test nodes: 4436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed_tr,pubmed = get_dataloader('pubmed')\n",
    "pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset citeseer\n",
      "\n",
      "Total number of nodes: 1663\n",
      "Total number of edges: 2308\n",
      "Number of train nodes: 749\n",
      "Number of validation nodes: 166\n",
      "Number of test nodes: 748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citeseer_tr,citeseer = get_dataloader('citeseer')\n",
    "citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset computers\n",
      "\n",
      "Total number of nodes: 6875\n",
      "Total number of edges: 122756\n",
      "Number of train nodes: 3093\n",
      "Number of validation nodes: 688\n",
      "Number of test nodes: 3094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[13752, 767], edge_index=[2, 491722], y=[13752])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computers_tr,computers = get_dataloader(dataset='computers')\n",
    "computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset photo\n",
      "\n",
      "Total number of nodes: 3822\n",
      "Total number of edges: 57836\n",
      "Number of train nodes: 1720\n",
      "Number of validation nodes: 382\n",
      "Number of test nodes: 1720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[7650, 745], edge_index=[2, 238162], y=[7650])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_tr, photo = get_dataloader(dataset='photo')\n",
    "photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset cs\n",
      "\n",
      "Total number of nodes: 9164\n",
      "Total number of edges: 40942\n",
      "Number of train nodes: 4124\n",
      "Number of validation nodes: 916\n",
      "Number of test nodes: 4124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[18333, 6805], edge_index=[2, 163788], y=[18333])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_tr,cs = get_dataloader('cs')\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset physics\n",
      "\n",
      "Total number of nodes: 17245\n",
      "Total number of edges: 124422\n",
      "Number of train nodes: 7761\n",
      "Number of validation nodes: 1724\n",
      "Number of test nodes: 7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[34493, 8415], edge_index=[2, 495924], y=[34493])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_tr,physics = get_dataloader('physics')\n",
    "physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset reddit\n",
      "\n",
      "Total number of nodes: 23278\n",
      "Total number of edges: 1102618\n",
      "Number of train nodes: 10475\n",
      "Number of validation nodes: 2328\n",
      "Number of test nodes: 10475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[232965, 602], edge_index=[2, 114615892], y=[232965], train_mask=[232965], val_mask=[232965], test_mask=[232965])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_tr,reddit = get_dataloader('reddit',mia_subsample_rate=.1)\n",
    "reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset github\n",
      "\n",
      "Total number of nodes: 18849\n",
      "Total number of edges: 140190\n",
      "Number of train nodes: 8482\n",
      "Number of validation nodes: 1885\n",
      "Number of test nodes: 8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[37700, 128], edge_index=[2, 578006], y=[37700])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_tr,github = get_dataloader('github',mia_subsample_rate=.5)\n",
    "github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset flickr\n",
      "\n",
      "Total number of nodes: 17846\n",
      "Total number of edges: 38482\n",
      "Number of train nodes: 8030\n",
      "Number of validation nodes: 1785\n",
      "Number of test nodes: 8031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[89250, 500], edge_index=[2, 899756], y=[89250], train_mask=[89250], val_mask=[89250], test_mask=[89250])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flickr_tr,flickr = get_dataloader('flickr',mia_subsample_rate=.2)\n",
    "flickr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get dataset lastfmasia\n",
      "\n",
      "Total number of nodes: 3808\n",
      "Total number of edges: 13820\n",
      "Number of train nodes: 1713\n",
      "Number of validation nodes: 381\n",
      "Number of test nodes: 1714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[7624, 128], edge_index=[2, 55612], y=[7624])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastfmasia_tr,lastfmasia = get_dataloader('lastfmasia')\n",
    "lastfmasia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dataset', 'Vanilla train acc', 'Vanilla train loss',\n",
       "       'Vanilla train f1', 'Vanilla test acc', 'Vanilla test loss',\n",
       "       'Vanilla test f1', 'Shadow train acc', 'Shadow train loss',\n",
       "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
       "       'Shadow test f1', 'MIA subsample rate', 'MIA mlp', 'MIA svm',\n",
       "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse',\n",
       "       'MIA confidence thr', 'MIA seed', 'Vanilla runtime per',\n",
       "       'Shadow runtime per', 'Epsilon', 'Delta', 'Dp', 'Rdp', 'Ldp',\n",
       "       'Norm bound', 'Noise scale', 'Sampler', 'Sampler batchsize',\n",
       "       'Occurance k', 'Cluster numparts', 'Saint rootnodes',\n",
       "       'Saint samplecoverage', 'Saint walklenth', 'Epochs', 'Shadow epochs',\n",
       "       'Num val', 'Num test', 'Layers', 'Hidden dims', 'Learning rate',\n",
       "       'Shadow learning rate', 'Dropout', 'Activation', 'Early stopping',\n",
       "       'Patience', 'Optim type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data,Dataset\n",
    "\n",
    "total_parms = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params_new.csv',index_col=0)\n",
    "\n",
    "from typing import List, Literal, Sequence, Union\n",
    "\n",
    "\n",
    "dataset_list = ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']\n",
    "def get_datasetwise_df(df:pd.DataFrame,name=None):\n",
    "    if not name:\n",
    "        dflist = []\n",
    "        for i in ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']:\n",
    "            dflist.append(df[df['Dataset']==i])\n",
    "        return dflist\n",
    "    else:\n",
    "        return df[df['Dataset']==name]\n",
    "\n",
    "def get_f1accs(df: Union[pd.DataFrame, List[pd.DataFrame]]):\n",
    "    metrics = ['Vanilla test acc','Vanilla test f1','Shadow test acc','Shadow test f1','MIA mlp', 'MIA svm',\n",
    "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse','Vanilla runtime per']\n",
    "    if isinstance(df,list):\n",
    "        res = []\n",
    "        for i in df:\n",
    "            res.append(i[metrics].max())\n",
    "        return res\n",
    "    else:\n",
    "        return df[metrics].max()\n",
    "    \n",
    "\n",
    "total_parms.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla train f1</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow train f1</th>\n",
       "      <th>...</th>\n",
       "      <th>Num test</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Hidden dims</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Shadow learning rate</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Early stopping</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Optim type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2248</td>\n",
       "      <td>2.4601</td>\n",
       "      <td>0.2248</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>2.4485</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>2.4512</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>2.4556</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>2.4577</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>2.4785</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>2.5045</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>2.4968</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>2.4971</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>2.5228</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>2.4923</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>2.4870</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>2.4675</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>2.4974</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>2.4535</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>2.4770</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>2.4565</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>2.4351</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>cs</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>2.4460</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>2.4591</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Vanilla train acc  Vanilla train loss  Vanilla train f1  \\\n",
       "470      cs             0.2248              2.4601            0.2248   \n",
       "471      cs             0.2250              2.4512            0.2250   \n",
       "472      cs             0.2117              2.4577            0.2117   \n",
       "473      cs             0.2211              2.5045            0.2211   \n",
       "474      cs             0.2156              2.4971            0.2156   \n",
       "475      cs             0.2165              2.4923            0.2165   \n",
       "476      cs             0.2076              2.4675            0.2076   \n",
       "477      cs             0.2258              2.4535            0.2258   \n",
       "478      cs             0.2231              2.4565            0.2231   \n",
       "479      cs             0.2219              2.4460            0.2219   \n",
       "\n",
       "     Vanilla test acc  Vanilla test loss  Vanilla test f1  Shadow train acc  \\\n",
       "470            0.2197             2.4485           0.2197            0.9988   \n",
       "471            0.2180             2.4556           0.2180            0.9998   \n",
       "472            0.2180             2.4785           0.2180            0.9988   \n",
       "473            0.2151             2.4968           0.2151            0.9998   \n",
       "474            0.2177             2.5228           0.2177            0.9995   \n",
       "475            0.2199             2.4870           0.2199            0.9981   \n",
       "476            0.2170             2.4974           0.2170            0.9990   \n",
       "477            0.2168             2.4770           0.2168            0.9990   \n",
       "478            0.2245             2.4351           0.2245            1.0000   \n",
       "479            0.2265             2.4591           0.2265            0.9993   \n",
       "\n",
       "     Shadow train loss  Shadow train f1  ...  Num test  Layers  Hidden dims  \\\n",
       "470             0.0042           0.9988  ...      0.45       2          256   \n",
       "471             0.0030           0.9998  ...      0.45       2          256   \n",
       "472             0.0051           0.9988  ...      0.45       2          256   \n",
       "473             0.0027           0.9998  ...      0.45       2          256   \n",
       "474             0.0031           0.9995  ...      0.45       2          256   \n",
       "475             0.0053           0.9981  ...      0.45       2          256   \n",
       "476             0.0040           0.9990  ...      0.45       2          256   \n",
       "477             0.0044           0.9990  ...      0.45       2          256   \n",
       "478             0.0025           1.0000  ...      0.45       2          256   \n",
       "479             0.0039           0.9993  ...      0.45       2          256   \n",
       "\n",
       "     Learning rate  Shadow learning rate  Dropout  Activation  Early stopping  \\\n",
       "470          0.001                 0.001      0.5        relu           False   \n",
       "471          0.001                 0.001      0.5        relu           False   \n",
       "472          0.001                 0.001      0.5        relu           False   \n",
       "473          0.001                 0.001      0.5        relu           False   \n",
       "474          0.001                 0.001      0.5        relu           False   \n",
       "475          0.001                 0.001      0.5        relu           False   \n",
       "476          0.001                 0.001      0.5        relu           False   \n",
       "477          0.001                 0.001      0.5        relu           False   \n",
       "478          0.001                 0.001      0.5        relu           False   \n",
       "479          0.001                 0.001      0.5        relu           False   \n",
       "\n",
       "     Patience  Optim type  \n",
       "470       100        adam  \n",
       "471       100        adam  \n",
       "472       100        adam  \n",
       "473       100        adam  \n",
       "474       100        adam  \n",
       "475       100        adam  \n",
       "476       100        adam  \n",
       "477       100        adam  \n",
       "478       100        adam  \n",
       "479       100        adam  \n",
       "\n",
       "[10 rows x 51 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_parms_dp = total_parms[total_parms['Ldp'] == True ]\n",
    "total_parms_dp[total_parms_dp['Dataset'] == 'cs']#['Epsilon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
