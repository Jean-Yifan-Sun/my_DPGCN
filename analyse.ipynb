{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dataset', 'Vanilla train acc', 'Vanilla train loss',\n",
       "       'Vanilla train f1', 'Vanilla test acc', 'Vanilla test loss',\n",
       "       'Vanilla test f1', 'Shadow train acc', 'Shadow train loss',\n",
       "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
       "       'Shadow test f1', 'MIA subsample rate', 'MIA mlp', 'MIA svm',\n",
       "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse',\n",
       "       'MIA confidence thr', 'MIA seed', 'Vanilla runtime per',\n",
       "       'Shadow runtime per', 'Epsilon', 'Delta', 'Dp', 'Rdp', 'Ldp',\n",
       "       'Norm bound', 'Noise scale', 'Sampler', 'Sampler batchsize',\n",
       "       'Occurance k', 'Cluster numparts', 'Saint rootnodes',\n",
       "       'Saint samplecoverage', 'Saint walklenth', 'Epochs', 'Shadow epochs',\n",
       "       'Num val', 'Num test', 'Layers', 'Hidden dims', 'Learning rate',\n",
       "       'Shadow learning rate', 'Dropout', 'Activation', 'Early stopping',\n",
       "       'Patience', 'Optim type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data,Dataset\n",
    "\n",
    "total_parms_new = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params_new.csv',index_col=0)\n",
    "total_parms = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params.csv',index_col=0)\n",
    "\n",
    "from typing import List, Literal, Sequence, Union\n",
    "\n",
    "\n",
    "dataset_list = ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']\n",
    "def get_datasetwise_df(df:pd.DataFrame,name=None):\n",
    "    if not name:\n",
    "        dflist = []\n",
    "        for i in ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']:\n",
    "            dflist.append(df[df['Dataset']==i])\n",
    "        return dflist\n",
    "    else:\n",
    "        return df[df['Dataset']==name]\n",
    "\n",
    "def get_f1accs(df: Union[pd.DataFrame, List[pd.DataFrame]]):\n",
    "    metrics = ['Vanilla test acc','Vanilla test f1','Shadow test acc','Shadow test f1','MIA mlp', 'MIA svm',\n",
    "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse','Vanilla runtime per']\n",
    "    if isinstance(df,list):\n",
    "        res = []\n",
    "        for i in df:\n",
    "            res.append(i[metrics].max())\n",
    "        return res\n",
    "    else:\n",
    "        return df[metrics].max()\n",
    "    \n",
    "\n",
    "total_parms_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(df:pd.DataFrame):\n",
    "    clean_adam = df[(df['Dp']==False)&(df['Rdp']==False)&(df['Ldp']==False)&(df['Optim type']=='adam')]\n",
    "    clean_sgd = df[(df['Dp']==False)&(df['Rdp']==False)&(df['Ldp']==False)&(df['Optim type']=='sgd')]\n",
    "    return clean_adam,clean_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_adam = total_parms[(total_parms['Dp']==False)&(total_parms['Rdp']==False)&(total_parms['Ldp']==False)&(total_parms['Optim type']=='adam')]\n",
    "clean_sgd = total_parms[(total_parms['Dp']==False)&(total_parms['Rdp']==False)&(total_parms['Ldp']==False)&(total_parms['Optim type']=='sgd')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla train f1</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow train f1</th>\n",
       "      <th>...</th>\n",
       "      <th>Num test</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Hidden dims</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Shadow learning rate</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Early stopping</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Optim type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Dataset, Vanilla train acc, Vanilla train loss, Vanilla train f1, Vanilla test acc, Vanilla test loss, Vanilla test f1, Shadow train acc, Shadow train loss, Shadow train f1, Shadow test acc, Shadow test loss, Shadow test f1, MIA subsample rate, MIA mlp, MIA svm, MIA ranfor, MIA logi, MIA ada, MIA confidence mse, MIA confidence thr, MIA seed, Vanilla runtime per, Shadow runtime per, Epsilon, Delta, Dp, Rdp, Ldp, Sampler, Sampler batchsize, Occurance k, Cluster numparts, Saint rootnodes, Saint samplecoverage, Saint walklenth, Epochs, Shadow epochs, Num val, Num test, Layers, Hidden dims, Learning rate, Shadow learning rate, Dropout, Activation, Early stopping, Patience, Optim type]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,clean_sgd = baseline(total_parms_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla train f1</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow train f1</th>\n",
       "      <th>...</th>\n",
       "      <th>Num test</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Hidden dims</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Shadow learning rate</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Early stopping</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Optim type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.6144</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.6010</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.5872</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>0.6153</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.7898</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.7898</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>github</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>0.3517</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>github</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.3518</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.3697</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>github</td>\n",
       "      <td>0.8621</td>\n",
       "      <td>0.3483</td>\n",
       "      <td>0.8621</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.3627</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>github</td>\n",
       "      <td>0.8535</td>\n",
       "      <td>0.3496</td>\n",
       "      <td>0.8535</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>0.3607</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>github</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.3543</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Vanilla train acc  Vanilla train loss  Vanilla train f1  \\\n",
       "510    cora             0.8933              0.5738            0.8933   \n",
       "511    cora             0.9031              0.6010            0.9031   \n",
       "512    cora             0.8785              0.6489            0.8785   \n",
       "513    cora             0.8818              0.6372            0.8818   \n",
       "514    cora             0.8851              0.6160            0.8851   \n",
       "..      ...                ...                 ...               ...   \n",
       "745  github             0.8576              0.3517            0.8576   \n",
       "746  github             0.8592              0.3518            0.8592   \n",
       "747  github             0.8621              0.3483            0.8621   \n",
       "748  github             0.8535              0.3496            0.8535   \n",
       "749  github             0.8566              0.3540            0.8566   \n",
       "\n",
       "     Vanilla test acc  Vanilla test loss  Vanilla test f1  Shadow train acc  \\\n",
       "510            0.7800             0.8644           0.7800            0.8916   \n",
       "511            0.8013             0.7987           0.8013            0.8916   \n",
       "512            0.7931             0.8245           0.7931            0.8736   \n",
       "513            0.7898             0.8272           0.7898            0.9015   \n",
       "514            0.8079             0.8025           0.8079            0.8785   \n",
       "..                ...                ...              ...               ...   \n",
       "745            0.8520             0.3686           0.8520            0.8527   \n",
       "746            0.8531             0.3697           0.8531            0.8518   \n",
       "747            0.8531             0.3627           0.8531            0.8471   \n",
       "748            0.8582             0.3594           0.8582            0.8553   \n",
       "749            0.8499             0.3729           0.8499            0.8593   \n",
       "\n",
       "     Shadow train loss  Shadow train f1  ...  Num test  Layers  Hidden dims  \\\n",
       "510             0.6144           0.8916  ...      0.45       2          256   \n",
       "511             0.5872           0.8916  ...      0.45       2          256   \n",
       "512             0.6153           0.8736  ...      0.45       2          256   \n",
       "513             0.5717           0.9015  ...      0.45       2          256   \n",
       "514             0.6212           0.8785  ...      0.45       2          256   \n",
       "..                 ...              ...  ...       ...     ...          ...   \n",
       "745             0.3649           0.8527  ...      0.45       2          256   \n",
       "746             0.3682           0.8518  ...      0.45       2          256   \n",
       "747             0.3733           0.8471  ...      0.45       2          256   \n",
       "748             0.3607           0.8553  ...      0.45       2          256   \n",
       "749             0.3543           0.8593  ...      0.45       2          256   \n",
       "\n",
       "     Learning rate  Shadow learning rate  Dropout  Activation  Early stopping  \\\n",
       "510           0.02                  0.02      0.5        relu           False   \n",
       "511           0.02                  0.02      0.5        relu           False   \n",
       "512           0.02                  0.02      0.5        relu           False   \n",
       "513           0.02                  0.02      0.5        relu           False   \n",
       "514           0.02                  0.02      0.5        relu           False   \n",
       "..             ...                   ...      ...         ...             ...   \n",
       "745           0.02                  0.02      0.5        relu           False   \n",
       "746           0.02                  0.02      0.5        relu           False   \n",
       "747           0.02                  0.02      0.5        relu           False   \n",
       "748           0.02                  0.02      0.5        relu           False   \n",
       "749           0.02                  0.02      0.5        relu           False   \n",
       "\n",
       "     Patience  Optim type  \n",
       "510       100         sgd  \n",
       "511       100         sgd  \n",
       "512       100         sgd  \n",
       "513       100         sgd  \n",
       "514       100         sgd  \n",
       "..        ...         ...  \n",
       "745       100         sgd  \n",
       "746       100         sgd  \n",
       "747       100         sgd  \n",
       "748       100         sgd  \n",
       "749       100         sgd  \n",
       "\n",
       "[90 rows x 51 columns]"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <th>Shadow test acc</th>\n",
       "      <th>Shadow test f1</th>\n",
       "      <th>MIA mlp</th>\n",
       "      <th>MIA svm</th>\n",
       "      <th>MIA ranfor</th>\n",
       "      <th>MIA logi</th>\n",
       "      <th>MIA ada</th>\n",
       "      <th>MIA confidence mse</th>\n",
       "      <th>Vanilla runtime per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cora</th>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.8112</td>\n",
       "      <td>0.8128</td>\n",
       "      <td>0.8128</td>\n",
       "      <td>0.5821</td>\n",
       "      <td>0.5936</td>\n",
       "      <td>0.5665</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citeseer</th>\n",
       "      <td>0.7219</td>\n",
       "      <td>0.7219</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.5813</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>0.5764</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>0.1805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubmed</th>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computers</th>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.8229</td>\n",
       "      <td>0.8229</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.5158</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.5193</td>\n",
       "      <td>0.5143</td>\n",
       "      <td>0.5192</td>\n",
       "      <td>0.1857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photo</th>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.5192</td>\n",
       "      <td>0.5192</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.1812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0.8312</td>\n",
       "      <td>0.8312</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.5171</td>\n",
       "      <td>0.5138</td>\n",
       "      <td>0.5139</td>\n",
       "      <td>0.1938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physics</th>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.9305</td>\n",
       "      <td>0.9305</td>\n",
       "      <td>0.5103</td>\n",
       "      <td>0.5132</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.5129</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>0.6953</td>\n",
       "      <td>0.6953</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.5141</td>\n",
       "      <td>0.5081</td>\n",
       "      <td>0.5121</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.5131</td>\n",
       "      <td>0.2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.5058</td>\n",
       "      <td>0.5083</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flickr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lastfmasia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vanilla test acc  Vanilla test f1  Shadow test acc  \\\n",
       "cora                  0.8112           0.8112           0.8128   \n",
       "citeseer              0.7219           0.7219           0.7380   \n",
       "pubmed                0.6105           0.6105           0.5940   \n",
       "computers             0.8251           0.8251           0.8229   \n",
       "photo                 0.9140           0.9140           0.9198   \n",
       "cs                    0.8312           0.8312           0.8303   \n",
       "physics               0.9343           0.9343           0.9305   \n",
       "reddit                0.6953           0.6953           0.6897   \n",
       "github                0.8582           0.8582           0.8592   \n",
       "flickr                   NaN              NaN              NaN   \n",
       "lastfmasia               NaN              NaN              NaN   \n",
       "\n",
       "            Shadow test f1  MIA mlp  MIA svm  MIA ranfor  MIA logi  MIA ada  \\\n",
       "cora                0.8128   0.5821   0.5936      0.5665    0.5468   0.5698   \n",
       "citeseer            0.7380   0.5926   0.5813      0.5739    0.5505   0.5764   \n",
       "pubmed              0.5940   0.5000   0.5050      0.5187    0.5108   0.5074   \n",
       "computers           0.8229   0.5130   0.5158      0.5112    0.5193   0.5143   \n",
       "photo               0.9198   0.5192   0.5192      0.5186    0.5221   0.5180   \n",
       "cs                  0.8303   0.5155   0.5170      0.5093    0.5171   0.5138   \n",
       "physics             0.9305   0.5103   0.5132      0.5054    0.5129   0.5096   \n",
       "reddit              0.6897   0.5077   0.5141      0.5081    0.5121   0.5112   \n",
       "github              0.8592   0.5058   0.5083      0.5086    0.5068   0.5093   \n",
       "flickr                 NaN      NaN      NaN         NaN       NaN      NaN   \n",
       "lastfmasia             NaN      NaN      NaN         NaN       NaN      NaN   \n",
       "\n",
       "            MIA confidence mse  Vanilla runtime per  \n",
       "cora                    0.6026               0.1845  \n",
       "citeseer                0.5952               0.1805  \n",
       "pubmed                  0.5123               0.1903  \n",
       "computers               0.5192               0.1857  \n",
       "photo                   0.5299               0.1812  \n",
       "cs                      0.5139               0.1938  \n",
       "physics                 0.5078               0.1977  \n",
       "reddit                  0.5131               0.2187  \n",
       "github                  0.5107               0.1815  \n",
       "flickr                     NaN                  NaN  \n",
       "lastfmasia                 NaN                  NaN  "
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_list = get_datasetwise_df(clean_sgd)\n",
    "\n",
    "clean_res_dfs = get_f1accs(clean_list)\n",
    "clean_res = {}\n",
    "for i in range(len(dataset_list)):\n",
    "    clean_res[dataset_list[i]] = clean_res_dfs[i].to_dict()\n",
    "pd.DataFrame(clean_res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
