{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dataset', 'Vanilla train acc', 'Vanilla train loss',\n",
       "       'Vanilla train f1', 'Vanilla test acc', 'Vanilla test loss',\n",
       "       'Vanilla test f1', 'Shadow train acc', 'Shadow train loss',\n",
       "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
       "       'Shadow test f1', 'MIA subsample rate', 'MIA mlp', 'MIA svm',\n",
       "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse',\n",
       "       'MIA confidence thr', 'MIA seed', 'Vanilla runtime per',\n",
       "       'Shadow runtime per', 'Epsilon', 'Delta', 'Dp', 'Rdp', 'Ldp',\n",
       "       'Norm bound', 'Noise scale', 'Sampler', 'Sampler batchsize',\n",
       "       'Occurance k', 'Cluster numparts', 'Saint rootnodes',\n",
       "       'Saint samplecoverage', 'Saint walklenth', 'Epochs', 'Shadow epochs',\n",
       "       'Num val', 'Num test', 'Layers', 'Hidden dims', 'Learning rate',\n",
       "       'Shadow learning rate', 'Dropout', 'Activation', 'Early stopping',\n",
       "       'Patience', 'Optim type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data,Dataset\n",
    "\n",
    "total_parms_new = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params_new.csv',index_col=0)\n",
    "total_parms = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params.csv',index_col=0)\n",
    "\n",
    "from typing import List, Literal, Sequence, Union\n",
    "\n",
    "\n",
    "dataset_list = ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']\n",
    "def get_datasetwise_df(df:pd.DataFrame,name=None):\n",
    "    if not name:\n",
    "        dflist = []\n",
    "        for i in ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']:\n",
    "            dflist.append(df[df['Dataset']==i])\n",
    "        return dflist\n",
    "    else:\n",
    "        return df[df['Dataset']==name]\n",
    "\n",
    "def get_f1accs(df: Union[pd.DataFrame, List[pd.DataFrame]]):\n",
    "    metrics = ['Vanilla test acc','Vanilla test f1','Shadow test acc','Shadow test f1','Norm bound','Noise scale','MIA mlp', 'MIA svm',\n",
    "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse','Vanilla runtime per']\n",
    "    criticals = ['Norm bound','Noise scale']\n",
    "    if isinstance(df,list):\n",
    "        res = []\n",
    "        for i in df:\n",
    "            res.append(i[metrics].max())\n",
    "        return res\n",
    "    else:\n",
    "        return df[metrics].max()\n",
    "    \n",
    "\n",
    "total_parms_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(df:pd.DataFrame):\n",
    "    clean_adam = df[(df['Dp']==True)&(df['Rdp']==False)&(df['Ldp']==False)&(df['Optim type']=='adam')]\n",
    "    clean_sgd = df[(df['Dp']==True)&(df['Rdp']==False)&(df['Ldp']==False)&(df['Optim type']=='sgd')]\n",
    "    return clean_adam,clean_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_adam,dp_sgd = baseline(total_parms_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Vanilla train acc</th>\n",
       "      <th>Vanilla train loss</th>\n",
       "      <th>Vanilla train f1</th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test loss</th>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <th>Shadow train acc</th>\n",
       "      <th>Shadow train loss</th>\n",
       "      <th>Shadow train f1</th>\n",
       "      <th>...</th>\n",
       "      <th>Num test</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Hidden dims</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Shadow learning rate</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Early stopping</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Optim type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>1.9439</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>1.9431</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>1.9461</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>1.9576</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1314</td>\n",
       "      <td>1.9493</td>\n",
       "      <td>0.1314</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>1.9502</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>1.9492</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.9524</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1806</td>\n",
       "      <td>1.9399</td>\n",
       "      <td>0.1806</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>1.9391</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>1.9467</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>1.9576</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1314</td>\n",
       "      <td>1.9561</td>\n",
       "      <td>0.1314</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>1.9496</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>1.9537</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>1.9537</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>1.9316</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>1.9281</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>cora</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>1.9312</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>1.9342</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>200</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Vanilla train acc  Vanilla train loss  Vanilla train f1  \\\n",
       "10     cora             0.1511              1.9439            0.1511   \n",
       "11     cora             0.1396              1.9461            0.1396   \n",
       "12     cora             0.1314              1.9493            0.1314   \n",
       "13     cora             0.1199              1.9492            0.1199   \n",
       "14     cora             0.1806              1.9399            0.1806   \n",
       "..      ...                ...                 ...               ...   \n",
       "755    cora             0.1166              1.9467            0.1166   \n",
       "756    cora             0.1314              1.9561            0.1314   \n",
       "757    cora             0.1379              1.9537            0.1379   \n",
       "758    cora             0.1494              1.9316            0.1494   \n",
       "759    cora             0.1823              1.9312            0.1823   \n",
       "\n",
       "     Vanilla test acc  Vanilla test loss  Vanilla test f1  Shadow train acc  \\\n",
       "10             0.1461             1.9431           0.1461            0.9984   \n",
       "11             0.1166             1.9576           0.1166            0.9951   \n",
       "12             0.1002             1.9502           0.1002            0.9885   \n",
       "13             0.1248             1.9524           0.1248            0.9967   \n",
       "14             0.1724             1.9391           0.1724            0.9967   \n",
       "..                ...                ...              ...               ...   \n",
       "755            0.1100             1.9576           0.1100            0.9984   \n",
       "756            0.1297             1.9496           0.1297            0.9984   \n",
       "757            0.1478             1.9537           0.1478            0.9967   \n",
       "758            0.1264             1.9281           0.1264            0.9967   \n",
       "759            0.1773             1.9342           0.1773            1.0000   \n",
       "\n",
       "     Shadow train loss  Shadow train f1  ...  Num test  Layers  Hidden dims  \\\n",
       "10              0.0296           0.9984  ...      0.45       2          256   \n",
       "11              0.0263           0.9951  ...      0.45       2          256   \n",
       "12              0.0441           0.9885  ...      0.45       2          256   \n",
       "13              0.0196           0.9967  ...      0.45       2          256   \n",
       "14              0.0345           0.9967  ...      0.45       2          256   \n",
       "..                 ...              ...  ...       ...     ...          ...   \n",
       "755             0.0133           0.9984  ...      0.45       2          256   \n",
       "756             0.0144           0.9984  ...      0.45       2          256   \n",
       "757             0.0127           0.9967  ...      0.45       2          256   \n",
       "758             0.0166           0.9967  ...      0.45       2          256   \n",
       "759             0.0084           1.0000  ...      0.45       2          256   \n",
       "\n",
       "     Learning rate  Shadow learning rate  Dropout  Activation  Early stopping  \\\n",
       "10           0.001                 0.001      0.0        relu            True   \n",
       "11           0.001                 0.001      0.0        relu            True   \n",
       "12           0.001                 0.001      0.0        relu            True   \n",
       "13           0.001                 0.001      0.0        relu            True   \n",
       "14           0.001                 0.001      0.0        relu            True   \n",
       "..             ...                   ...      ...         ...             ...   \n",
       "755          0.001                 0.001      0.5        relu            True   \n",
       "756          0.001                 0.001      0.5        relu            True   \n",
       "757          0.001                 0.001      0.5        relu            True   \n",
       "758          0.001                 0.001      0.5        relu            True   \n",
       "759          0.001                 0.001      0.5        relu            True   \n",
       "\n",
       "     Patience  Optim type  \n",
       "10        100        adam  \n",
       "11        100        adam  \n",
       "12        100        adam  \n",
       "13        100        adam  \n",
       "14        100        adam  \n",
       "..        ...         ...  \n",
       "755       200        adam  \n",
       "756       200        adam  \n",
       "757       200        adam  \n",
       "758       200        adam  \n",
       "759       200        adam  \n",
       "\n",
       "[260 rows x 51 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vanilla test acc</th>\n",
       "      <th>Vanilla test f1</th>\n",
       "      <th>Shadow test acc</th>\n",
       "      <th>Shadow test f1</th>\n",
       "      <th>Norm bound</th>\n",
       "      <th>Noise scale</th>\n",
       "      <th>MIA mlp</th>\n",
       "      <th>MIA svm</th>\n",
       "      <th>MIA ranfor</th>\n",
       "      <th>MIA logi</th>\n",
       "      <th>MIA ada</th>\n",
       "      <th>MIA confidence mse</th>\n",
       "      <th>Vanilla runtime per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cora</th>\n",
       "      <td>0.5928</td>\n",
       "      <td>0.5928</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.5386</td>\n",
       "      <td>0.5213</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.6904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citeseer</th>\n",
       "      <td>0.3128</td>\n",
       "      <td>0.3128</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pubmed</th>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.4833</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>0.8530</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computers</th>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.5153</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photo</th>\n",
       "      <td>0.7337</td>\n",
       "      <td>0.7337</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.5177</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0.5124</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.5012</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.2745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physics</th>\n",
       "      <td>0.6932</td>\n",
       "      <td>0.6932</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.5091</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.2738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>0.4095</td>\n",
       "      <td>0.4095</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5032</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.5084</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5041</td>\n",
       "      <td>0.5044</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.5041</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flickr</th>\n",
       "      <td>0.3703</td>\n",
       "      <td>0.3703</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5025</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.5043</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.5061</td>\n",
       "      <td>0.5084</td>\n",
       "      <td>0.2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lastfmasia</th>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.5073</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.5111</td>\n",
       "      <td>0.5197</td>\n",
       "      <td>0.2390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Vanilla test acc  Vanilla test f1  Shadow test acc  \\\n",
       "cora                  0.5928           0.5928           0.8243   \n",
       "citeseer              0.3128           0.3128           0.6992   \n",
       "pubmed                0.4833           0.4833           0.8530   \n",
       "computers             0.6332           0.6332           0.9053   \n",
       "photo                 0.7337           0.7337           0.9395   \n",
       "cs                    0.5124           0.5124           0.9069   \n",
       "physics               0.6932           0.6932           0.9521   \n",
       "reddit                0.4095           0.4095           0.9188   \n",
       "github                0.8054           0.8054           0.8628   \n",
       "flickr                0.3703           0.3703           0.4352   \n",
       "lastfmasia            0.5268           0.5268           0.8285   \n",
       "\n",
       "            Shadow test f1  Norm bound  Noise scale  MIA mlp  MIA svm  \\\n",
       "cora                0.8243         5.0          4.0   0.5033   0.5082   \n",
       "citeseer            0.6992         2.0          3.0   0.5000   0.5013   \n",
       "pubmed              0.8530         2.0          3.0   0.5001   0.5014   \n",
       "computers           0.9053         2.0          3.0   0.5110   0.5086   \n",
       "photo               0.9395         2.0          3.0   0.5067   0.5177   \n",
       "cs                  0.9069         2.0          3.0   0.5004   0.5012   \n",
       "physics             0.9521         2.0          3.0   0.5001   0.5031   \n",
       "reddit              0.9188         2.0          1.0   0.5032   0.5045   \n",
       "github              0.8628         2.0          1.0   0.5041   0.5044   \n",
       "flickr              0.4352         2.0          1.0   0.5025   0.5047   \n",
       "lastfmasia          0.8285         2.0          1.0   0.5106   0.5088   \n",
       "\n",
       "            MIA ranfor  MIA logi  MIA ada  MIA confidence mse  \\\n",
       "cora            0.5238    0.5386   0.5213              0.6026   \n",
       "citeseer        0.5000    0.5142   0.5000              0.5349   \n",
       "pubmed          0.5036    0.5013   0.5004              0.5107   \n",
       "computers       0.5047    0.5153   0.5062              0.5156   \n",
       "photo           0.5142    0.5189   0.5096              0.5299   \n",
       "cs              0.5002    0.5113   0.5004              0.5113   \n",
       "physics         0.5001    0.5091   0.5005              0.5082   \n",
       "reddit          0.5033    0.5084   0.5040              0.5093   \n",
       "github          0.5054    0.5024   0.5041              0.5110   \n",
       "flickr          0.5043    0.5086   0.5061              0.5084   \n",
       "lastfmasia      0.5073    0.5214   0.5111              0.5197   \n",
       "\n",
       "            Vanilla runtime per  \n",
       "cora                     0.6904  \n",
       "citeseer                 0.2614  \n",
       "pubmed                   0.2691  \n",
       "computers                0.2570  \n",
       "photo                    0.2585  \n",
       "cs                       0.2745  \n",
       "physics                  0.2738  \n",
       "reddit                   0.2375  \n",
       "github                   0.2207  \n",
       "flickr                   0.2314  \n",
       "lastfmasia               0.2390  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_list = get_datasetwise_df(dp_adam)\n",
    "\n",
    "clean_res_dfs = get_f1accs(clean_list)\n",
    "clean_res = {}\n",
    "for i in range(len(dataset_list)):\n",
    "    clean_res[dataset_list[i]] = clean_res_dfs[i].to_dict()\n",
    "pd.DataFrame(clean_res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = clean_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_drop(df:pd.DataFrame):\n",
    "    labels = ['Vanilla train acc','Vanilla train loss','Vanilla train f1',\n",
    "          'Shadow train acc', 'Shadow train loss',\n",
    "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
    "       'Shadow test f1', 'MIA subsample rate','MIA seed','Shadow runtime per', 'Num val', 'Num test', 'Layers', 'Hidden dims','Activation','Shadow learning rate','Dropout','Sampler', 'Sampler batchsize',\n",
    "       'Occurance k', 'Cluster numparts', 'Saint rootnodes',\n",
    "       'Saint samplecoverage', 'Saint walklenth','Rdp','Ldp']\n",
    "    return df.drop(columns=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_dp(cora:pd.DataFrame):\n",
    "    maxx = ['Vanilla test acc','Vanilla test f1']\n",
    "    meann = ['Vanilla runtime per','MIA mlp', 'MIA svm','MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse','Epsilon','Delta']\n",
    "    minn = ['Epsilon','Delta']\n",
    "    res = {}\n",
    "   \n",
    "    for k in maxx:\n",
    "        res[k] = cora.max()[k]\n",
    "    for k in meann:\n",
    "        res[k] = cora.mean(numeric_only=True)[k]\n",
    "    for k in minn:\n",
    "        res[k] = cora.min()[k]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.3128,\n",
       " 'Vanilla test f1': 0.3128,\n",
       " 'Vanilla runtime per': 0.18936000000000003,\n",
       " 'MIA mlp': 0.5,\n",
       " 'MIA svm': 0.5000666666666667,\n",
       " 'MIA ranfor': 0.5,\n",
       " 'MIA logi': 0.49779666666666667,\n",
       " 'MIA ada': 0.5,\n",
       " 'MIA confidence mse': 0.51288,\n",
       " 'Epsilon': 103.3026,\n",
       " 'Delta': 0.1}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora = dp_drop(clean_list[1])\n",
    "cora_ns1 = cora[cora['Noise scale']==1]\n",
    "get_res_dp(cora_ns1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': nan,\n",
       " 'Vanilla test f1': nan,\n",
       " 'Vanilla runtime per': nan,\n",
       " 'MIA mlp': nan,\n",
       " 'MIA svm': nan,\n",
       " 'MIA ranfor': nan,\n",
       " 'MIA logi': nan,\n",
       " 'MIA ada': nan,\n",
       " 'MIA confidence mse': nan,\n",
       " 'Epsilon': nan,\n",
       " 'Delta': nan}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cora = dp_drop(clean_list[2])\n",
    "cora_ns1 = cora[cora['Noise scale']==2]\n",
    "get_res_dp(cora_ns1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.2326,\n",
       " 'Vanilla test f1': 0.2326,\n",
       " 'Vanilla runtime per': 0.25606,\n",
       " 'MIA mlp': 0.5,\n",
       " 'MIA svm': 0.5,\n",
       " 'MIA ranfor': 0.5,\n",
       " 'MIA logi': 0.5004,\n",
       " 'MIA ada': 0.5,\n",
       " 'MIA confidence mse': 0.5050799999999999,\n",
       " 'Epsilon': 24.6359,\n",
       " 'Delta': 0.1}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cora = dp_drop(clean_list[2])\n",
    "cora_ns1 = cora[cora['Noise scale']==3]\n",
    "get_res_dp(cora_ns1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': nan,\n",
       " 'Vanilla test f1': nan,\n",
       " 'Vanilla runtime per': nan,\n",
       " 'MIA mlp': nan,\n",
       " 'MIA svm': nan,\n",
       " 'MIA ranfor': nan,\n",
       " 'MIA logi': nan,\n",
       " 'MIA ada': nan,\n",
       " 'MIA confidence mse': nan,\n",
       " 'Epsilon': nan,\n",
       " 'Delta': nan}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cora = dp_drop(clean_list[0])\n",
    "cora_ns1 = cora[cora['Noise scale']==4]\n",
    "get_res_dp(cora_ns1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
