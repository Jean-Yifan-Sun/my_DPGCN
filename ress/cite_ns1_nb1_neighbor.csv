,Dataset,Vanilla train acc,Vanilla train loss,Vanilla train f1,Vanilla test acc,Vanilla test loss,Vanilla test f1,Shadow train acc,Shadow train loss,Shadow train f1,Shadow test acc,Shadow test loss,Shadow test f1,MIA subsample rate,MIA mlp,MIA svm,MIA ranfor,MIA logi,MIA ada,MIA confidence mse,MIA confidence thr,MIA seed,Vanilla runtime per,Shadow runtime per,Epsilon,Delta,Dp,Rdp,Ldp,Norm bound,Noise scale,Sampler,Sampler batchsize,Occurance k,Cluster numparts,Saint rootnodes,Saint samplecoverage,Saint walklenth,Epochs,Shadow epochs,Num val,Num test,Layers,Hidden dims,Learning rate,Shadow learning rate,Dropout,Activation,Early stopping,Patience,Optim type
0,citeseer,0.9359,0.1563,0.9359,0.7193,0.9425,0.7193,0.9853,0.029,0.9853,0.6484,1.8539,0.6484,0.5,0.6113,0.6084,0.5506,0.5062,0.5406,0.6573,0.02,123454321,0.9035,0.1855,96.9356,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,253,222,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
1,citeseer,0.9226,0.1847,0.9226,0.7099,0.9797,0.7099,0.984,0.0299,0.984,0.6925,1.7467,0.6925,0.5,0.618,0.6325,0.5627,0.5077,0.5534,0.6673,0.05,246908642,0.903,0.1827,99.959,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,264,223,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
2,citeseer,0.9332,0.1611,0.9332,0.6925,0.9741,0.6925,0.988,0.0255,0.988,0.6738,1.6438,0.6738,0.5,0.5854,0.6098,0.5573,0.5223,0.542,0.658,0.02,370362963,0.9031,0.1714,102.1578,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,272,223,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
3,citeseer,0.9559,0.1239,0.9559,0.7179,1.0198,0.7179,0.9853,0.0315,0.9853,0.6832,1.7936,0.6832,0.5,0.6247,0.6137,0.564,0.501,0.556,0.6787,0.02,493817284,0.9388,0.1834,97.4853,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,255,223,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
4,citeseer,0.9466,0.1547,0.9466,0.7112,1.0157,0.7112,0.9866,0.0327,0.9866,0.639,1.8156,0.639,0.5,0.6347,0.5997,0.544,0.4777,0.5373,0.6673,0.02,617271605,0.8979,0.1867,98.5847,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,259,227,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
5,citeseer,0.9386,0.145,0.9386,0.7259,0.9421,0.7259,0.9893,0.0283,0.9893,0.6671,1.7169,0.6671,0.5,0.6433,0.6258,0.5707,0.5057,0.5647,0.6787,0.02,740725926,0.901,0.1829,98.8595,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,260,222,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
6,citeseer,0.9279,0.1648,0.9279,0.7219,0.9317,0.7219,0.9853,0.0268,0.9853,0.6765,1.6721,0.6765,0.5,0.6053,0.5998,0.5467,0.5069,0.536,0.674,0.02,864180247,0.8998,0.1828,98.035,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,257,227,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
7,citeseer,0.9439,0.1482,0.9439,0.7273,0.9457,0.7273,0.984,0.0318,0.984,0.6564,1.765,0.6564,0.5,0.654,0.6124,0.562,0.511,0.5633,0.6706,0.02,987634568,0.9031,0.1844,98.035,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,257,224,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
8,citeseer,0.9266,0.1694,0.9266,0.7206,1.0423,0.7206,0.9866,0.0302,0.9866,0.6684,1.7409,0.6684,0.5,0.5833,0.6084,0.5566,0.4997,0.544,0.6646,0.02,1111088889,0.8946,0.1821,104.6315,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,281,224,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
9,citeseer,0.9399,0.1546,0.9399,0.7005,1.0748,0.7005,0.9866,0.0289,0.9866,0.6698,1.5881,0.6698,0.5,0.6533,0.6338,0.5834,0.4770,0.5747,0.6787,0.0200,1234543210,0.8956,0.1818,105.1812,0.0001,False,True,False,1.0,1.0,neighbor,0.4,20,30.0,5,50,3,283,220,0.1,0.45,2,256,0.002,0.001,0.5,relu,True,200,adam
