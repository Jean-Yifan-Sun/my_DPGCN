{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd1/sunyifan/conda/mygcn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Dataset', 'Vanilla train acc', 'Vanilla train loss',\n",
       "       'Vanilla train f1', 'Vanilla test acc', 'Vanilla test loss',\n",
       "       'Vanilla test f1', 'Shadow train acc', 'Shadow train loss',\n",
       "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
       "       'Shadow test f1', 'MIA subsample rate', 'MIA mlp', 'MIA svm',\n",
       "       'MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse',\n",
       "       'MIA confidence thr', 'MIA seed', 'Vanilla runtime per',\n",
       "       'Shadow runtime per', 'Epsilon', 'Delta', 'Dp', 'Rdp', 'Ldp',\n",
       "       'Norm bound', 'Noise scale', 'Sampler', 'Sampler batchsize',\n",
       "       'Occurance k', 'Cluster numparts', 'Saint rootnodes',\n",
       "       'Saint samplecoverage', 'Saint walklenth', 'Epochs', 'Shadow epochs',\n",
       "       'Num val', 'Num test', 'Layers', 'Hidden dims', 'Learning rate',\n",
       "       'Shadow learning rate', 'Dropout', 'Activation', 'Early stopping',\n",
       "       'Patience', 'Optim type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data,Dataset\n",
    "\n",
    "total_parms_new = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params_new.csv',index_col=0)\n",
    "total_parms = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/total_params.csv',index_col=0)\n",
    "\n",
    "from typing import List, Literal, Sequence, Union\n",
    "\n",
    "\n",
    "dataset_list = ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']\n",
    "\n",
    "def get_datasetwise_df(df:pd.DataFrame,name=None):\n",
    "    if not name:\n",
    "        dflist = []\n",
    "        for i in ['cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia']:\n",
    "            dflist.append(df[df['Dataset']==i])\n",
    "        return dflist\n",
    "    else:\n",
    "        return df[df['Dataset']==name]\n",
    "\n",
    "def baseline(df:pd.DataFrame):\n",
    "    clean_adam = df[(df['Dp']==False)&(df['Rdp']==True)&(df['Ldp']==False)&(df['Optim type']=='adam')]\n",
    "    clean_sgd = df[(df['Dp']==False)&(df['Rdp']==True)&(df['Ldp']==False)&(df['Optim type']=='sgd')]\n",
    "    return clean_adam,clean_sgd\n",
    "\n",
    "def rdp_drop(df:pd.DataFrame):\n",
    "    labels = ['Vanilla train acc','Vanilla train loss','Vanilla train f1',\n",
    "          'Shadow train acc', 'Shadow train loss',\n",
    "       'Shadow train f1', 'Shadow test acc', 'Shadow test loss',\n",
    "       'Shadow test f1', 'MIA subsample rate','MIA seed','Shadow runtime per', 'Num val', 'Num test', 'Layers', 'Hidden dims','Activation','Shadow learning rate','Dropout','Sampler','Dp','Rdp','Ldp']\n",
    "    return df.drop(columns=labels)\n",
    "\n",
    "def get_res_rdp(cora:pd.DataFrame):\n",
    "    maxx = ['Vanilla test acc','Vanilla test f1']\n",
    "    meann = ['Vanilla runtime per','MIA mlp', 'MIA svm','MIA ranfor', 'MIA logi', 'MIA ada', 'MIA confidence mse','Epsilon','Delta']\n",
    "    minn = ['Epsilon','Delta']\n",
    "    res = {}\n",
    "   \n",
    "    for k in maxx:\n",
    "        res[k] = cora.max()[k]\n",
    "    for k in meann:\n",
    "        res[k] = cora.mean(numeric_only=True)[k]\n",
    "    for k in minn:\n",
    "        res[k] = cora.mean(numeric_only=True)[k]\n",
    "    return res\n",
    "    \n",
    "\n",
    "total_parms_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'cora','citeseer','pubmed','computers','photo','cs','physics','reddit','github','flickr','lastfmasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640    cluster\n",
       "Name: Sampler, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadfs = get_datasetwise_df(total_parms_new)\n",
    "cora,_ = baseline(datadfs[6])\n",
    "cora['Sampler'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1491    0.2\n",
       "Name: Sampler batchsize, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_ad_d = cora[(cora['Sampler']=='occurance')]\n",
    "cora_ad_d['Sampler batchsize'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1491    1.0\n",
       "Name: Noise scale, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_ad_d['Noise scale'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1491    2.0\n",
       "Name: Norm bound, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_ad_d['Norm bound'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1491    10\n",
       "Name: Occurance k, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_ad_d['Occurance k'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.4307,\n",
       " 'Vanilla test f1': 0.4307,\n",
       " 'Vanilla runtime per': 2.86062,\n",
       " 'MIA mlp': 0.51176,\n",
       " 'MIA svm': 0.51212,\n",
       " 'MIA ranfor': 0.5119,\n",
       " 'MIA logi': 0.5009399999999999,\n",
       " 'MIA ada': 0.51406,\n",
       " 'MIA confidence mse': 0.5382100000000001,\n",
       " 'Epsilon': 32.041760000000004,\n",
       " 'Delta': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_rdp(cora_ad_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.2\n",
       "Name: Sampler batchsize, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/ress/cs_ns2_nb1_occurance.csv',index_col=0)\n",
    "df['Sampler batchsize'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "Name: Noise scale, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Noise scale'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "Name: Occurance k, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Occurance k'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.918,\n",
       " 'Vanilla test f1': 0.918,\n",
       " 'Vanilla runtime per': 1.7381571428571427,\n",
       " 'MIA mlp': 0.5133142857142857,\n",
       " 'MIA svm': 0.5102857142857143,\n",
       " 'MIA ranfor': 0.5093142857142857,\n",
       " 'MIA logi': 0.5116999999999999,\n",
       " 'MIA ada': 0.5127571428571428,\n",
       " 'MIA confidence mse': 0.518957142857143,\n",
       " 'Epsilon': 26.853457142857145,\n",
       " 'Delta': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "od1 = df[(df['Occurance k']==20)&(df['Sampler batchsize']==.2)&(df['Noise scale']==1)]\n",
    "get_res_rdp(od1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.2\n",
       "Name: Sampler batchsize, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/mnt/ssd1/sunyifan/WorkStation/dpuf/my_DPGCN/ress/cs_ns2_nb1_neighbor.csv',index_col=0)\n",
    "df['Sampler batchsize'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "Name: Noise scale, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Noise scale'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vanilla test acc': 0.9134,\n",
       " 'Vanilla test f1': 0.9134,\n",
       " 'Vanilla runtime per': 2.0372,\n",
       " 'MIA mlp': 0.5219,\n",
       " 'MIA svm': 0.5209,\n",
       " 'MIA ranfor': 0.5096,\n",
       " 'MIA logi': 0.5119,\n",
       " 'MIA ada': 0.5154,\n",
       " 'MIA confidence mse': 0.5286,\n",
       " 'Epsilon': 35.8937,\n",
       " 'Delta': 0.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_rdp(df[(df['Sampler batchsize']==.2)&(df['Noise scale']==2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
